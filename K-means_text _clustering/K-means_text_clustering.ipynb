{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name : Dharanidharan Ramaamy Karuppanaamy\n",
    "# SUID  :  320028178"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The input file is read and only the review comments are collected. Once the review comments are collected we are cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=[]\n",
    "with open(\"ipfile.txt\", \"r\", encoding=\"latin-1\") as f:\n",
    "     for line in f:\n",
    "            reviews=line.split(\":\")\n",
    "            if(reviews[0]=='review/text'):\n",
    "                d.append([reviews[1].replace(\"\\n\",\"\")])\n",
    "only_reviews = [item for sublist in d for item in sublist]\n",
    "reviewss=[]\n",
    "for i in only_reviews:\n",
    "    reviewss.append(i.replace(\"<br />\",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Using RegexpTokenizer we are removing the special characters in the reviews\n",
    "# 2. L gives the unique set of values that we get after splitting the review sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "hi=[]\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for i in reviewss:\n",
    "    hi.append(tokenizer.tokenize(i))\n",
    "ss = [item for sublist in hi for item in sublist]\n",
    "L = set(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11507\n"
     ]
    }
   ],
   "source": [
    "print(len(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Removing from L all stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwordsstring = \"a<br>able<br>about<br>above<br>abst<br>accordance<br>according<br>accordingly<br>across<br>act<br>actually<br>added<br>adj<br>affected<br>affecting<br>affects<br>after<br>afterwards<br>again<br>against<br>ah<br>all<br>almost<br>alone<br>along<br>already<br>also<br>although<br>always<br>am<br>among<br>amongst<br>an<br>and<br>announce<br>another<br>any<br>anybody<br>anyhow<br>anymore<br>anyone<br>anything<br>anyway<br>anyways<br>anywhere<br>apparently<br>approximately<br>are<br>aren<br>arent<br>arise<br>around<br>as<br>aside<br>ask<br>asking<br>at<br>auth<br>available<br>away<br>awfully<br>b<br>back<br>be<br>became<br>because<br>become<br>becomes<br>becoming<br>been<br>before<br>beforehand<br>begin<br>beginning<br>beginnings<br>begins<br>behind<br>being<br>believe<br>below<br>beside<br>besides<br>between<br>beyond<br>biol<br>both<br>brief<br>briefly<br>but<br>by<br>c<br>ca<br>came<br>can<br>cannot<br>can't<br>cause<br>causes<br>certain<br>certainly<br>co<br>com<br>come<br>comes<br>contain<br>containing<br>contains<br>could<br>couldnt<br>d<br>date<br>did<br>didn't<br>different<br>do<br>does<br>doesn't<br>doing<br>done<br>don't<br>down<br>downwards<br>due<br>during<br>e<br>each<br>ed<br>edu<br>effect<br>eg<br>eight<br>eighty<br>either<br>else<br>elsewhere<br>end<br>ending<br>enough<br>especially<br>et<br>et-al<br>etc<br>even<br>ever<br>every<br>everybody<br>everyone<br>everything<br>everywhere<br>ex<br>except<br>f<br>far<br>few<br>ff<br>fifth<br>first<br>five<br>fix<br>followed<br>following<br>follows<br>for<br>former<br>formerly<br>forth<br>found<br>four<br>from<br>further<br>furthermore<br>g<br>gave<br>get<br>gets<br>getting<br>give<br>given<br>gives<br>giving<br>go<br>goes<br>gone<br>got<br>gotten<br>h<br>had<br>happens<br>hardly<br>has<br>hasn't<br>have<br>haven't<br>having<br>he<br>hed<br>hence<br>her<br>here<br>hereafter<br>hereby<br>herein<br>heres<br>hereupon<br>hers<br>herself<br>hes<br>hi<br>hid<br>him<br>himself<br>his<br>hither<br>home<br>how<br>howbeit<br>however<br>hundred<br>i<br>id<br>ie<br>if<br>i'll<br>im<br>immediate<br>immediately<br>importance<br>important<br>in<br>inc<br>indeed<br>index<br>information<br>instead<br>into<br>invention<br>inward<br>is<br>isn't<br>it<br>itd<br>it'll<br>its<br>itself<br>i've<br>j<br>just<br>k<br>keep<br>keeps<br>kept<br>kg<br>km<br>know<br>known<br>knows<br>l<br>largely<br>last<br>lately<br>later<br>latter<br>latterly<br>least<br>less<br>lest<br>let<br>lets<br>like<br>liked<br>likely<br>line<br>little<br>'ll<br>look<br>looking<br>looks<br>ltd<br>m<br>made<br>mainly<br>make<br>makes<br>many<br>may<br>maybe<br>me<br>mean<br>means<br>meantime<br>meanwhile<br>merely<br>mg<br>might<br>million<br>miss<br>ml<br>more<br>moreover<br>most<br>mostly<br>mr<br>mrs<br>much<br>mug<br>must<br>my<br>myself<br>n<br>na<br>name<br>namely<br>nay<br>nd<br>near<br>nearly<br>necessarily<br>necessary<br>need<br>needs<br>neither<br>never<br>nevertheless<br>new<br>next<br>nine<br>ninety<br>no<br>nobody<br>non<br>none<br>nonetheless<br>noone<br>nor<br>normally<br>nos<br>not<br>noted<br>nothing<br>now<br>nowhere<br>o<br>obtain<br>obtained<br>obviously<br>of<br>off<br>often<br>oh<br>ok<br>okay<br>old<br>omitted<br>on<br>once<br>one<br>ones<br>only<br>onto<br>or<br>ord<br>other<br>others<br>otherwise<br>ought<br>our<br>ours<br>ourselves<br>out<br>outside<br>over<br>overall<br>owing<br>own<br>p<br>page<br>pages<br>part<br>particular<br>particularly<br>past<br>per<br>perhaps<br>placed<br>please<br>plus<br>poorly<br>possible<br>possibly<br>potentially<br>pp<br>predominantly<br>present<br>previously<br>primarily<br>probably<br>promptly<br>proud<br>provides<br>put<br>q<br>que<br>quickly<br>quite<br>qv<br>r<br>ran<br>rather<br>rd<br>re<br>readily<br>really<br>recent<br>recently<br>ref<br>refs<br>regarding<br>regardless<br>regards<br>related<br>relatively<br>research<br>respectively<br>resulted<br>resulting<br>results<br>right<br>run<br>s<br>said<br>same<br>saw<br>say<br>saying<br>says<br>sec<br>section<br>see<br>seeing<br>seem<br>seemed<br>seeming<br>seems<br>seen<br>self<br>selves<br>sent<br>seven<br>several<br>shall<br>she<br>shed<br>she'll<br>shes<br>should<br>shouldn't<br>show<br>showed<br>shown<br>showns<br>shows<br>significant<br>significantly<br>similar<br>similarly<br>since<br>six<br>slightly<br>so<br>some<br>somebody<br>somehow<br>someone<br>somethan<br>something<br>sometime<br>sometimes<br>somewhat<br>somewhere<br>soon<br>sorry<br>specifically<br>specified<br>specify<br>specifying<br>still<br>stop<br>strongly<br>sub<br>substantially<br>successfully<br>such<br>sufficiently<br>suggest<br>sup<br>sure<br>t<br>take<br>taken<br>taking<br>tell<br>tends<br>th<br>than<br>thank<br>thanks<br>thanx<br>that<br>that'll<br>thats<br>that've<br>the<br>their<br>theirs<br>them<br>themselves<br>then<br>thence<br>there<br>thereafter<br>thereby<br>thered<br>therefore<br>therein<br>there'll<br>thereof<br>therere<br>theres<br>thereto<br>thereupon<br>there've<br>these<br>they<br>theyd<br>they'll<br>theyre<br>they've<br>think<br>this<br>those<br>thou<br>though<br>thoughh<br>thousand<br>throug<br>through<br>throughout<br>thru<br>thus<br>til<br>tip<br>to<br>together<br>too<br>took<br>toward<br>towards<br>tried<br>tries<br>truly<br>try<br>trying<br>ts<br>twice<br>two<br>u<br>un<br>under<br>unfortunately<br>unless<br>unlike<br>unlikely<br>until<br>unto<br>up<br>upon<br>ups<br>us<br>use<br>used<br>useful<br>usefully<br>usefulness<br>uses<br>using<br>usually<br>v<br>value<br>various<br>'ve<br>very<br>via<br>viz<br>vol<br>vols<br>vs<br>w<br>want<br>wants<br>was<br>wasnt<br>way<br>we<br>wed<br>welcome<br>we'll<br>went<br>were<br>werent<br>we've<br>what<br>whatever<br>what'll<br>whats<br>when<br>whence<br>whenever<br>where<br>whereafter<br>whereas<br>whereby<br>wherein<br>wheres<br>whereupon<br>wherever<br>whether<br>which<br>while<br>whim<br>whither<br>who<br>whod<br>whoever<br>whole<br>who'll<br>whom<br>whomever<br>whos<br>whose<br>why<br>widely<br>willing<br>wish<br>with<br>within<br>without<br>wont<br>words<br>world<br>would<br>wouldnt<br>www<br>x<br>y<br>yes<br>yet<br>you<br>youd<br>you'll<br>your<br>youre<br>yours<br>yourself<br>yourselves<br>you've<br>z<br>zero\"\n",
    "stopwordslist = stopwordsstring.split(\"<br>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W=[]\n",
    "for i in L:\n",
    "    if (i.lower() not in stopwordslist):\n",
    "        W.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting the number of times each word in W appears among all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "emplis=[]\n",
    "onlywords=[]\n",
    "for i in W:\n",
    "    tot = 0\n",
    "    for j in reviewss:\n",
    "        for k in j.split():\n",
    "            if k == i:\n",
    "                tot = tot+1\n",
    "    if len(i)>2:\n",
    "        emplis.append((i,tot))\n",
    "sorted_words = sorted(emplis, key=lambda x: x[1], reverse = True)\n",
    "top500= sorted_words[:500]\n",
    "for i in top500:\n",
    "    onlywords.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('good', 613), ('chips', 602), ('taste', 520), ('love', 508), ('great', 502), ('will', 464), ('flavor', 444), ('product', 425), ('tea', 381), ('find', 325), ('food', 317), ('buy', 315), ('bag', 270), ('best', 270), ('better', 256), ('time', 243), ('eat', 240), ('price', 230), ('coffee', 218), ('flavors', 211), ('bought', 210), ('Amazon', 203), ('potato', 202), ('order', 198), ('recommend', 185), ('water', 180), ('bags', 176), ('mix', 169), ('ordered', 164), ('sugar', 163), ('bit', 161), ('favorite', 161), ('add', 152), ('dog', 149), ('salt', 148), ('box', 147), ('well', 146), ('drink', 146), ('tastes', 135), ('small', 135), ('local', 132), ('lot', 126), ('quality', 125), ('easy', 123), ('nice', 122), ('sweet', 122), ('eating', 122), ('green', 122), ('regular', 122), ('hard', 121), ('pretty', 118), ('store', 117), ('brand', 115), ('Kettle', 114), ('fresh', 114), ('loves', 113), ('healthy', 112), ('enjoy', 112), ('hot', 112), ('pack', 110), ('purchased', 109), ('Great', 107), ('size', 107), ('snack', 106), ('perfect', 106), ('going', 104), ('grocery', 103), ('big', 103), ('thought', 100), ('chip', 100), ('definitely', 100), ('cup', 98), ('long', 97), ('buying', 96), ('variety', 96), ('family', 95), ('chocolate', 95), ('loved', 95), ('high', 93), ('case', 92), ('products', 92), ('ingredients', 90), ('free', 90), ('tasty', 90), ('years', 89), ('happy', 89), ('bad', 88), ('thing', 87), ('low', 87), ('delicious', 87), ('tasted', 86), ('dogs', 86), ('full', 82), ('highly', 82), ('reviews', 82), ('strong', 81), ('worth', 81), ('popcorn', 81), ('stuff', 80), ('real', 79), ('people', 78), ('wonderful', 78), ('received', 78), ('natural', 78), ('shipping', 77), ('drinking', 77), ('husband', 77), ('fat', 76), ('coconut', 75), ('brands', 75), ('tasting', 74), ('year', 74), ('half', 74), ('amount', 74), ('wanted', 73), ('things', 73), ('day', 71), ('feel', 70), ('item', 69), ('purchase', 69), ('work', 69), ('excellent', 68), ('ordering', 68), ('arrived', 68), ('texture', 66), ('making', 66), ('expensive', 66), ('open', 65), ('absolutely', 63), ('started', 63), ('decided', 63), ('light', 63), ('cream', 63), ('calories', 62), ('couple', 62), ('baby', 62), ('oil', 61), ('son', 61), ('health', 61), ('white', 61), ('organic', 61), ('vinegar', 61), ('fact', 59), ('fruit', 58), ('foods', 58), ('stores', 57), ('cheaper', 57), ('calorie', 57), ('large', 57), ('powder', 56), ('flavored', 56), ('salty', 56), ('100', 54), ('Salt', 53), ('kids', 53), ('alternative', 53), ('package', 53), ('three', 53), ('sauce', 53), ('rice', 52), ('juice', 52), ('healthier', 51), ('cans', 51), ('treat', 51), ('corn', 51), ('Good', 51), ('glad', 51), ('likes', 51), ('top', 50), ('diet', 50), ('Love', 50), ('money', 50), ('kind', 49), ('spicy', 49), ('read', 49), ('problem', 49), ('plastic', 48), ('review', 47), ('energy', 47), ('dry', 47), ('looked', 46), ('plain', 46), ('fan', 46), ('cheese', 46), ('friends', 46), ('milk', 46), ('single', 46), ('works', 46), ('bitter', 45), ('mixed', 45), ('crunchy', 45), ('months', 45), ('Chips', 45), ('longer', 45), ('pepper', 45), ('deal', 45), ('tomatoes', 45), ('extra', 44), ('cut', 44), ('prefer', 44), ('pancakes', 44), ('iced', 44), ('daughter', 43), ('serving', 43), ('baked', 43), ('LOVE', 43), ('disappointed', 43), ('super', 43), ('peanut', 42), ('pancake', 42), ('bottle', 42), ('black', 41), ('company', 41), ('save', 41), ('type', 41), ('cook', 41), ('waffles', 40), ('pleased', 40), ('smaller', 40), ('cats', 40), ('smooth', 40), ('online', 40), ('cold', 39), ('label', 39), ('side', 39), ('dark', 39), ('brown', 39), ('treats', 39), ('smell', 39), ('meal', 38), ('canned', 38), ('cookies', 38), ('cake', 38), ('boxes', 38), ('quick', 38), ('sour', 38), ('opened', 38), ('gift', 38), ('weight', 38), ('enjoyed', 38), ('needed', 38), ('cat', 38), ('days', 37), ('BBQ', 37), ('chicken', 37), ('stars', 37), ('candy', 36), ('easily', 36), ('month', 36), ('times', 36), ('higher', 36), ('shipped', 36), ('pop', 36), ('waffle', 35), ('snacks', 35), ('rest', 35), ('Thai', 35), ('packets', 35), ('second', 35), ('ginger', 35), ('discovered', 35), ('surprised', 34), ('artificial', 34), ('packet', 34), ('breakfast', 34), ('ice', 34), ('bottom', 34), ('packaged', 34), ('exactly', 34), ('instant', 33), ('idea', 33), ('help', 33), ('pasta', 33), ('blend', 33), ('guess', 33), ('pay', 33), ('stevia', 33), ('difficult', 33), ('cooked', 33), ('left', 33), ('teas', 33), ('larger', 33), ('rich', 33), ('ate', 33), ('week', 33), ('Vinegar', 33), ('ago', 33), ('noticed', 33), ('carry', 33), ('called', 32), ('sea', 32), ('mouth', 32), ('morning', 32), ('soup', 32), ('finally', 32), ('hint', 32), ('entire', 31), ('reason', 31), ('cherry', 31), ('Will', 31), ('packaging', 31), ('tiny', 31), ('care', 31), ('version', 31), ('Brand', 31), ('pineapple', 31), ('pieces', 31), ('cost', 31), ('feed', 31), ('Popchips', 31), ('formula', 30), ('raw', 30), ('drinks', 30), ('throw', 30), ('meat', 30), ('recipe', 30), ('vanilla', 30), ('stay', 30), ('recommended', 30), ('sold', 30), ('simply', 30), ('items', 30), ('amazon', 30), ('syrup', 30), ('noodles', 30), ('adding', 29), ('stick', 29), ('expect', 29), ('extremely', 29), ('amazing', 29), ('potatoes', 29), ('list', 29), ('lots', 29), ('ingredient', 29), ('fine', 29), ('hand', 28), ('eaten', 28), ('weeks', 28), ('delivered', 28), ('butter', 28), ('flavorful', 28), ('cooking', 28), ('loose', 28), ('told', 28), ('Organic', 28), ('place', 28), ('air', 28), ('subscribe', 28), ('original', 28), ('clean', 27), ('excited', 27), ('baking', 27), ('fast', 27), ('plan', 27), ('takes', 27), ('crunch', 27), ('Best', 27), ('purchasing', 27), ('licorice', 27), ('individual', 26), ('cereal', 26), ('mild', 26), ('waste', 26), ('helps', 26), ('fun', 26), ('knew', 26), ('experience', 26), ('packed', 26), ('Farms', 25), ('flour', 25), ('normal', 25), ('olive', 25), ('cheap', 25), ('change', 25), ('kettle', 25), ('honey', 25), ('spice', 25), ('red', 25), ('unique', 25), ('sodium', 25), ('live', 25), ('completely', 25), ('serve', 25), ('cheddar', 25), ('heard', 25), ('lemon', 25), ('oatmeal', 25), ('color', 24), ('crisp', 24), ('feeding', 24), ('continue', 24), ('hope', 24), ('start', 24), ('close', 24), ('mind', 24), ('lunch', 24), ('huge', 24), ('shipment', 24), ('leave', 24), ('greasy', 24), ('protein', 23), ('switched', 23), ('inside', 23), ('ounce', 23), ('wife', 23), ('special', 23), ('trans', 23), ('soft', 23), ('bottles', 23), ('stuck', 23), ('minutes', 23), ('wheat', 23), ('thick', 23), ('Christmas', 23), ('cups', 23), ('bulk', 23), ('bowl', 23), ('wrong', 23), ('pound', 23), ('forward', 23), ('container', 23), ('problems', 23), ('convenient', 23), ('microwave', 23), ('Harmony', 22), ('Green', 22), ('training', 22), ('clear', 22), ('decent', 22), ('delivery', 22), ('content', 22), ('broken', 22), ('gourmet', 22), ('herbs', 22), ('glass', 22), ('paid', 22), ('expecting', 22), ('lollipops', 22), ('cinnamon', 22), ('packs', 22), ('reading', 22), ('mine', 22), ('pet', 21), ('hoping', 21), ('San', 21), ('gluten', 21), ('served', 21), ('fair', 21), ('Pop', 21), ('easier', 21), ('service', 21), ('house', 21), ('share', 21), ('choice', 21), ('nuts', 21), ('compared', 21), ('overly', 21), ('consistency', 21), ('remember', 21), ('beans', 21), ('stock', 21), ('beat', 21), ('popped', 21), ('eats', 21), ('balance', 21), ('changed', 21), ('apple', 21), ('jar', 21), ('kernels', 21), ('sale', 20), ('expected', 20), ('finding', 20), ('picked', 20), ('totally', 20), ('combination', 20), ('bigger', 20), ('mint', 20), ('reasonable', 20), ('Coconut', 20), ('crackers', 20), ('Stonewall', 20), ('portion', 20), ('brought', 20), ('hit', 20), ('addition', 20), ('awesome', 20), ('Weight', 20), ('based', 20), ('mixes', 20), ('kick', 20), ('liquid', 20), ('sort', 20), ('fairly', 20), ('Red', 20), ('filled', 20), ('pick', 20), ('lower', 19), ('packages', 19), ('website', 19), ('bits', 19)]\n"
     ]
    }
   ],
   "source": [
    "print(top500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "outerlist=[]\n",
    "for i in top500:\n",
    "    innerlist=[]\n",
    "    for j in reviewss:\n",
    "        count1=0\n",
    "        for k in j.split(): \n",
    "            if (i[0] == k.lower()):\n",
    "                count1=count1+1\n",
    "        innerlist.append(count1)\n",
    "    outerlist.append(innerlist)\n",
    "matrix = np.array(outerlist)\n",
    "matrixT = matrix.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering the vectorized reviews into 10 clusters using k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(matrixT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = np.array(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "top5= centers.tolist()\n",
    "print(len(top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('chips', 1.6756756756756759), ('flavor', 0.5045045045045047), ('salt', 0.441441441441441), ('great', 0.3693693693693695), ('potato', 0.3468468468468472)], [('great', 0.20655487804878073), ('product', 0.15396341463414634), ('taste', 0.15015243902439093), ('find', 0.10746951219512157), ('best', 0.10594512195121944)], [('food', 2.4769230769230774), ('dog', 1.0923076923076909), ('dogs', 0.5230769230769228), ('good', 0.3384615384615386), ('eat', 0.3384615384615386)], [('dog', 9.0), ('food', 4.666666666666667), ('dogs', 2.3333333333333335), ('natural', 2.333333333333333), ('foods', 1.6666666666666667)], [('tea', 3.028846153846154), ('green', 0.7884615384615391), ('drink', 0.40384615384615324), ('flavor', 0.32692307692307687), ('water', 0.30769230769230804)], [('coconut', 13.0), ('pineapple', 11.0), ('water', 10.0), ('drink', 4.0), ('natural', 4.0)], [('will', 1.1241830065359477), ('product', 0.2712418300653596), ('buy', 0.23529411764705904), ('great', 0.1862745098039216), ('taste', 0.1830065359477125)], [('chips', 4.800000000000001), ('potato', 1.9333333333333336), ('kettle', 1.499999999999999), ('brand', 1.2666666666666675), ('bag', 1.0000000000000002)], [('love', 1.291428571428575), ('great', 0.30285714285714305), ('taste', 0.19142857142857148), ('find', 0.15428571428571417), ('will', 0.14571428571428566)], [('good', 1.2706185567010384), ('taste', 0.22164948453608255), ('price', 0.14690721649484564), ('great', 0.14432989690721676), ('product', 0.1443298969072165)]]\n"
     ]
    }
   ],
   "source": [
    "clustervalues = []\n",
    "for i in top5:\n",
    "    lis=zip(onlywords,i)\n",
    "    sorted_top5 = sorted(lis, key=lambda x: x[1], reverse = True)\n",
    "    finaltop5 = sorted_top5[:5]\n",
    "    clustervalues.append(finaltop5)\n",
    "print(clustervalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<zip object at 0x000000EFE5AE4688>, <zip object at 0x000000EFE5AE4E08>, <zip object at 0x000000EFE5AE4308>, <zip object at 0x000000EFE5AE5BC8>, <zip object at 0x000000EFE5AE5C08>, <zip object at 0x000000EFE5AE5188>, <zip object at 0x000000EFE5B53348>, <zip object at 0x000000EFE5B53308>, <zip object at 0x000000EFE5B08888>, <zip object at 0x000000EFE5AE5748>]\n",
      "[[('food', 3.0), ('chubby', 2.0), ('higher', 2.0), ('boy', 2.0), ('going', 1.0)], [('good', 0.22807017543859648), ('great', 0.2105263157894737), ('product', 0.1929824561403509), ('oatmeal', 0.14035087719298245), ('taffy', 0.10526315789473696)], [('product', 4.0), ('water', 3.0), ('endurolyte', 3.0), ('nice', 2.0), ('desert', 2.0)], [('oatmeal', 5.0), ('instant', 4.0), ('good', 2.0), ('water', 2.0), ('sugar', 2.0)], [('oatmeal', 3.0), ('cooks', 3.0), ('water', 2.0), ('variety', 2.0), ('well', 2.0)], [('hot', 3.0), ('sauce', 3.0), ('love', 2.0), ('bottle', 2.0), ('tequila', 2.0)], [('taste', 2.0), ('earth', 2.0), ('good', 1.0), ('water', 1.0), ('sugar', 1.0)], [('sugar', 3.0), ('good', 2.0), ('oatmeal', 2.0), ('better', 2.0), ('best', 2.0)], [('instant', 4.0), ('oatmeal', 2.0), ('good', 1.0), ('water', 1.0), ('time', 1.0)], [('will', 2.0), ('ordinary', 2.0), ('peanuts', 2.0), ('nose', 2.0), ('jaw', 2.0)]]\n"
     ]
    }
   ],
   "source": [
    "clustervalues = []\n",
    "for i in top5:\n",
    "    lis=zip(onlywords,i)\n",
    "    clustervalues.append(lis)\n",
    "print(clustervalues)\n",
    "final_words=[]\n",
    "for i in clustervalues:\n",
    "    sorted_top5 = sorted(i, key=lambda x: x[1], reverse = True)\n",
    "    final_words_ = sorted_top5[:5]\n",
    "    final_words.append(final_words_)\n",
    "print(final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
